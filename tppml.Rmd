Activity quality  predictions
=============================

Load necessary libraries
```{r}
library(caret);
library(randomForest);
```

Load raw training data
```{r}
rawData <- read.csv("pml-training.csv", na.strings=c("NA", "#DIV/0!"), stringsAsFactors = FALSE);
```

Leave only variables that contain useful data: actual readings form the
sensors.
```{r}
usefulVarNames <- c("roll_belt","pitch_belt","yaw_belt","total_accel_belt",
                    "gyros_belt_x","gyros_belt_y","gyros_belt_z",
                    "accel_belt_x","accel_belt_y","accel_belt_z",
                    "magnet_belt_x","magnet_belt_y","magnet_belt_z",
                    "roll_arm","pitch_arm","yaw_arm","total_accel_arm",
                    "gyros_arm_x","gyros_arm_y","gyros_arm_z","accel_arm_x",
                    "accel_arm_y","accel_arm_z","magnet_arm_x",
                    "magnet_arm_y","magnet_arm_z","roll_dumbbell",
                    "pitch_dumbbell","yaw_dumbbell","total_accel_dumbbell",
                    "gyros_dumbbell_x","gyros_dumbbell_y",
                    "gyros_dumbbell_z","accel_dumbbell_x",
                    "accel_dumbbell_y","accel_dumbbell_z",
                    "magnet_dumbbell_x","magnet_dumbbell_y",
                    "magnet_dumbbell_z","roll_forearm","pitch_forearm",
                    "yaw_forearm","total_accel_forearm","gyros_forearm_x",
                    "gyros_forearm_y","gyros_forearm_z","accel_forearm_x",
                    "accel_forearm_y","accel_forearm_z","magnet_forearm_x",
                    "magnet_forearm_y","magnet_forearm_z","classe");
uData <-rawData[usefulVarNames];
```

Make sure that "classe" is categorical.
```{r}
uData$classe = as.factor(uData$classe)
```

Split the data into the training and testing sets for cross validation.
```{r}
inTrain = createDataPartition(y = uData$classe,p=0.7,list=FALSE);
training = uData[inTrain,];
testing = uData[-inTrain,];
```

Train the model using random forests and data from the training set
```{r}
modFit <- randomForest(classe ~.,data = training);
```

Use the model to calculate accuracy on the training set
```{r}
predictionsTraining <- predict(modFit,data = training);
confusionMatrix(predictionsTraining,training$classe)
```

Accuracy an training set is very high. This may be caused by overfitting.
Do the cross validation on the testing set to se if this is the case.

```{r}
predictionsTesting <- predict(modFit,newdata = testing);
confusionMatrix(predictionsTesting,testing$classe)
```

Cross validation results results are similiar to those in the training set.
Propably we are not suffering from overfitting. This proves that the method
that was chosen: randoms forests performs extremelly well for this problem.
Looking at the cross validation result I expect te out of sample error to be very low.

